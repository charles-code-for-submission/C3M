{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import os\n",
    "my_bucket = os.getenv(\"WORKSPACE_BUCKET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load rsid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "personids = pickle.load( open('personids.pkl', 'rb'))\n",
    "patient_cols = [str(int(i)) for i in personids if pd.notnull(i)]\n",
    "print(len(patient_cols), patient_cols[:3]) \n",
    "select_snps = pickle.load(open('select_snps.pkl', 'rb'))\n",
    "gwas_snps = select_snps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fetch locations of snps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chr_list = gwas_snps['CHR_ID'].values.tolist()\n",
    "chr_pos_list = gwas_snps['CHR_POS'].values.tolist()\n",
    "rsid_list = gwas_snps['SNPS'].values.tolist()\n",
    "\n",
    "failload_rowcount = 0\n",
    "select_snps = []\n",
    "for i in  range(len(chr_list)):\n",
    "    chrID =  str( chr_list[i] )\n",
    "    chr_pos = str(chr_pos_list[i])\n",
    "    rsid = str(rsid_list[i] )\n",
    "\n",
    "    try:\n",
    "        if ';' in chrID:\n",
    "            split_chrID = [c.strip() for c in chrID.split(';')]\n",
    "            split_chr_pos = [cp.strip() for cp in chr_pos.split(';')]\n",
    "            split_rsid = [r.strip() for r in rsid.split(';')]\n",
    "\n",
    "            tuples = [(j,k, l) for j,k,l in zip(split_chrID, split_chr_pos, split_rsid)]\n",
    "            select_snps.extend(tuples)\n",
    "        elif 'x' in chrID and chrID != 'X':\n",
    "            split_chrID = [c.strip() for c in chrID.split('x')]\n",
    "            split_chr_pos = [cp.strip() for cp in chr_pos.split('x')]\n",
    "            split_rsid = [r.strip() for r in rsid.split('x')]\n",
    "\n",
    "            tuples = [(j,k, l) for j,k,l in zip(split_chrID, split_chr_pos, split_rsid)]\n",
    "            select_snps.extend(tuples)\n",
    "        elif ' - ' in chrID:\n",
    "            split_chrID = [c.strip() for c in chrID.split('-')]\n",
    "            split_chr_pos = [cp.strip() for cp in chr_pos.split('-')]\n",
    "            split_rsid = [r.strip() for r in rsid.split('-')]\n",
    "\n",
    "            tuples = [(j,k, l) for j,k,l in zip(split_chrID, split_chr_pos, split_rsid)]\n",
    "            select_snps.extend(tuples)\n",
    "        else:\n",
    "            select_snps.append((chrID, chr_pos, rsid))\n",
    "    except:\n",
    "        print(i,type( chrID), type( chr_pos),type(  rsid))\n",
    "\n",
    "        failload_rowcount += 1\n",
    "        flag = 55\n",
    "        \n",
    "print(failload_rowcount) # 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_location = pd.DataFrame(select_snps)\n",
    "gwas_location.columns = ['chrom', 'pos', 'rsid']\n",
    "print(gwas_location.shape)  \n",
    "\n",
    "gwas_location = gwas_location[gwas_location.chrom!='nan']\n",
    "print(gwas_location.shape)  \n",
    "\n",
    "gwas_location_unique = gwas_location.drop_duplicates()\n",
    "print('gwas_location_unique', gwas_location_unique.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  convert to locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_snps_location = gwas_location_unique[['chrom', 'pos', 'rsid']]\n",
    "get_snps_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import hail as hl\n",
    "get_snps_location['chrom'] = 'chr' + get_snps_location['chrom']\n",
    "ht_loci = hl.Table.from_pandas(get_snps_location)\n",
    "\n",
    "ht_loci = ht_loci.annotate(locus=hl.locus(ht_loci.chrom, ht_loci.pos, reference_genome='GRCh38'))\n",
    "ht_loci = ht_loci.key_by('locus')\n",
    "ht_loci.show(n=5)\n",
    "print(\"Number of rows:\", ht_loci.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# query gene data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load srWGS acaf hail-split and select cols and rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "gen_path = os.getenv(\"WGS_ACAF_THRESHOLD_SPLIT_HAIL_PATH\")\n",
    "gen_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "mt = hl.read_matrix_table(gen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.describe(widget=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('filter columns for personids', len(patient_cols))\n",
    "patient_mt = mt.filter_cols(hl.literal(patient_cols).contains(mt.s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_locus_set = [locus for locus in ht_loci.locus.collect()]\n",
    "print('to locus ', len(to_locus_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "batch_size = 100\n",
    "batches  = [to_locus_set[i:i + batch_size] for i in range(0, len(to_locus_set), batch_size)]\n",
    "print('Total batches:', len(batches))\n",
    "\n",
    "batches = batches\n",
    "for b, batch_locus_set in tqdm(enumerate(batches)):\n",
    "\n",
    "    locus_set = hl.literal(batch_locus_set)\n",
    "    \n",
    "    filtered_mt = patient_mt.filter_rows(locus_set.contains(patient_mt.locus))\n",
    "    print(f'After  filter: {filtered_mt.count_rows()} rows')\n",
    "    entries_df = filtered_mt.entries()\n",
    "\n",
    "    entries_df = entries_df.key_by()\n",
    "\n",
    "    selected_entries = entries_df.select(\n",
    "        entries_df.locus,\n",
    "        entries_df.alleles,\n",
    "        entries_df.s,\n",
    "        entries_df.GT,\n",
    "    )\n",
    "    \n",
    "    selected_entries.export(f'genetic_data/variant_{b}.tsv.bgz')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
