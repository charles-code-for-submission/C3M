{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b432fb8e",
   "metadata": {},
   "source": [
    "## get all patient IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07674f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d48111d",
   "metadata": {},
   "source": [
    "obtain all involved samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b749358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "personids = pickle.load(open('personids.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c096e0",
   "metadata": {},
   "source": [
    "# basic input feature preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad756f44",
   "metadata": {},
   "source": [
    "demographic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a8caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "demographics = pickle.load(open('NewHome/demographics.pkl', 'rb'))\n",
    "demographics.drop_duplicates(inplace=True)\n",
    "\n",
    "def map_eth(x):\n",
    "    if x == 38003564:\n",
    "        return 'Not Hispanic'\n",
    "    elif x == 38003563:\n",
    "        return 'Hispanic'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "demographics['Ethnicity'] = demographics['ethnicity_concept_id'].apply(map_eth )\n",
    "\n",
    "\n",
    "def map_gender(x):\n",
    "    if x == 'Female':\n",
    "        return 'F'\n",
    "    elif x == 'Male':\n",
    "        return 'M'\n",
    "    else:\n",
    "        return None\n",
    "demographics['Gender'] = demographics['gender'].apply(map_gender )\n",
    "\n",
    "demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faaa553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "demographics = demographics[demographics['person_id'].isin(personids)]\n",
    "print(demographics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb6055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_csv0 = demographics[['person_id', 'date_of_birth']]\n",
    "\n",
    "demographics_csv1 = demographics[['person_id', 'date_of_birth', 'Ethnicity']]\n",
    "\n",
    "demographics_csv2 = demographics[['person_id', 'date_of_birth','Gender']]\n",
    "\n",
    "demographics_csv0.drop_duplicates(inplace=True)\n",
    "demographics_csv1.drop_duplicates(inplace=True)\n",
    "demographics_csv2.drop_duplicates(inplace=True)\n",
    "\n",
    "demographics_csv0['date_of_birth'] = demographics_csv0['date_of_birth'].dt.date\n",
    "demographics_csv1['date_of_birth'] = demographics_csv1['date_of_birth'].dt.date\n",
    "demographics_csv2['date_of_birth'] = demographics_csv2['date_of_birth'].dt.date\n",
    "\n",
    "\n",
    "demographics_csv0.dropna(subset=['date_of_birth'], inplace=True)\n",
    "demographics_csv1.dropna(subset=['Ethnicity'], inplace=True)\n",
    "demographics_csv2.dropna(subset=['Gender'], inplace=True)\n",
    "\n",
    "print('demographics_csv0', demographics_csv0.shape)\n",
    "\n",
    "print('demographics_csv1', demographics_csv1.shape, 'demographics_csv2', demographics_csv2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f55be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_csv0 = demographics_csv0.rename(columns = {'person_id':'patient_id','date_of_birth':'start'})\n",
    "\n",
    "demographics_csv1 = demographics_csv1.rename(columns = {'person_id':'patient_id','date_of_birth':'start', 'Ethnicity':'code'})\n",
    "demographics_csv2 = demographics_csv2.rename(columns = {'person_id':'patient_id','date_of_birth':'start', 'Gender':'code'})\n",
    "\n",
    "demographics_csv0['code']= 'Birth/Birth'\n",
    "demographics_csv1['code']= 'Ethnicity/' + demographics_csv1['code']\n",
    "demographics_csv2['code']= 'Gender/' + demographics_csv2['code']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda595df",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_csv = pd.concat([demographics_csv0, demographics_csv1, demographics_csv2], axis=0)\n",
    "demographics_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e2d7f1",
   "metadata": {},
   "source": [
    "mapping vacabulary harmorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aba3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load definition code\n",
    "\n",
    "code = pd.read_csv('NewHome/ADRD_dx_med_codes.csv',  index_col=0)\n",
    "code_icd10 = code[code.Code_type=='ICD-10'].Code.values.tolist()\n",
    "code_icd10 = [i.strip() for i in code_icd10]\n",
    "print('ICD code', len(code_icd10))\n",
    "\n",
    "code_rxcui = code[code.Code_type=='RXCUI'].Code.values.tolist()\n",
    "code_rxcui = [i.strip() for i in code_rxcui]\n",
    "print('RXCUI code', len(code_rxcui))\n",
    "\n",
    "snomed_2_icd10 = pd.read_csv('NewHome/csv_filter_mapping_snomed_to_Icd10cm.csv',  index_col=0)[['referencedComponentId', 'mapTarget']].drop_duplicates()\n",
    "print('Load mapping from snomed_2_icd10 and drop duplicates :', snomed_2_icd10.shape)\n",
    "\n",
    "\n",
    "code_snomed = []\n",
    "\n",
    "for c10 in code_icd10: \n",
    "    c_snomed = snomed_2_icd10[snomed_2_icd10['mapTarget'] == c10].referencedComponentId.values.tolist()\n",
    "    code_snomed.extend(c_snomed)\n",
    "\n",
    "code_snomed = list(set(code_snomed))\n",
    "code_snomed = [str(i) for i in code_snomed]\n",
    "\n",
    "exc_code_snomed = ['SNOMED/' + str(cid) for cid in code_snomed]\n",
    "exc_code_rxcui = ['RxNorm/' + str(cid) for cid in code_rxcui]\n",
    "\n",
    "assert not any([' ' in c for c in exc_code_snomed])\n",
    "assert not any([' ' in c for c in exc_code_rxcui])\n",
    "\n",
    "print('SNOMED code', len(exc_code_snomed))\n",
    "print('RXCUI code', len(exc_code_rxcui))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41cb5d3",
   "metadata": {},
   "source": [
    " diagnosis information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8623e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dxdata = pickle.load(open('NewHome/dxdata.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dxmotor = dxdata[dxdata['person_id'].isin(set(personids))]\n",
    "print('dxmotor (for the cohort)', dxmotor.shape)\n",
    "\n",
    "dxmotor = dxmotor[['person_id', 'condition_start_date', 'concept_code']]\\\n",
    ".rename(columns={'condition_start_date':'start', 'concept_code':'code', 'person_id':'patient_id'})\n",
    "\n",
    "\n",
    "dxmotor = dxmotor[~dxmotor['code'].isin(set(code_snomed))]\n",
    "print('dxmotor (remove adrd snomed codes)', dxmotor.shape)\n",
    "\n",
    "dxmotor['code'] = 'SNOMED/' + dxmotor['code']\n",
    "\n",
    "dxmotor.drop_duplicates(inplace=True)\n",
    "display(dxmotor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c647f26e",
   "metadata": {},
   "source": [
    "medication information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e27ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxdata = pickle.load(open('NewHome/drugdata_ingredient.pkl', 'rb'))\n",
    "\n",
    "rxmotor = rxdata[rxdata['person_id'].isin(set(personids))]\n",
    "print('rxmotor (for the cohort)', rxmotor.shape)\n",
    "\n",
    "rxmotor = rxmotor[['person_id', 'drug_exposure_start_date', 'RXCUI_ingredient']]\\\n",
    ".rename(columns={'drug_exposure_start_date':'start', 'RXCUI_ingredient':'code', 'person_id':'patient_id'})\n",
    "\n",
    "rxmotor = rxmotor[~rxmotor['code'].isin(set(code_rxcui))]\n",
    "print('rxmotor (remove adrd rxcui codes)', rxmotor.shape)\n",
    "\n",
    "rxmotor['code'] = 'RxNorm/' + rxmotor['code']\n",
    "\n",
    "rxmotor.drop_duplicates(inplace=True)\n",
    "display(rxmotor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45588ad5",
   "metadata": {},
   "source": [
    "# filter observation window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de250842",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_feature_for_psm_match(input_psm_match_collection, input_match_cci_collection, match_ratio):\n",
    "    \n",
    "    def summary(_input_psm_match_collection, match_ratio):\n",
    "        index=0\n",
    "        sample_summary_df = pd.DataFrame(columns=[\"type\", \"num_samples\", \"cp\", \"year\"]) \n",
    "        cps = [1]\n",
    "        years = [0, 1, 2, 5, 10]\n",
    "\n",
    "        for year in years:\n",
    "            for cp in cps:\n",
    "                _match_df = _input_psm_match_collection['ADRD_filter_cci_match_and_index_obs{}'.format(str(year))]\n",
    "                selected_columns = ['psm_control_{}'.format(str(mi)) for mi in range(1, match_ratio+1)]\n",
    "\n",
    "                _match_df[selected_columns] = _match_df[selected_columns].astype('Int64')\n",
    "\n",
    "                values_list = list(set(_match_df[selected_columns].values.flatten().tolist()))\n",
    "\n",
    "                case_row = [\"Case\", _match_df.index.nunique(), \"CP \"+ str(cp), str(year) + \"-yr Prediction Window\"] \n",
    "                control_row = [\"Control\",  len(values_list),  \"CP \"+ str(cp), str(year) + \"-yr Prediction Window\"]\n",
    "                sample_summary_df.loc[index] = case_row\n",
    "                index += 1\n",
    "                sample_summary_df.loc[index] = control_row\n",
    "                index += 1\n",
    "        display(sample_summary_df)\n",
    "        \n",
    "        \n",
    "    def format_psm_match(_input_psm_match_collection, match_ratio):\n",
    "        obs_years = [0, 1, 2, 5, 10]\n",
    "        _psm_match_collection = {}\n",
    "        for year in obs_years:\n",
    "            _match_df = _input_psm_match_collection['ADRD_filter_cci_match_and_index_obs{}'.format(str(year))]\n",
    "            selected_columns = ['psm_control_{}'.format(str(mi)) for mi in range(1, match_ratio+1)]\n",
    "\n",
    "            _match_df[selected_columns] = _match_df[selected_columns].astype('Int64')\n",
    "\n",
    "            _psm_match_collection['ADRD_filter_cci_match_and_index_obs{}'.format(str(year))] = _match_df\n",
    "\n",
    "        return _psm_match_collection      \n",
    "        \n",
    "        \n",
    "    def format_case_control_list(_input_psm_match_collection, _input_match_cci_collection, match_ratio):\n",
    "        years = [0, 1, 2, 5, 10]\n",
    "        cps = [1]\n",
    "        _cases_list = {}\n",
    "        _controls_list = {}\n",
    "        \n",
    "        for year in years:\n",
    "            for cp in cps:\n",
    "                all_df = _input_psm_match_collection['ADRD_filter_cci_match_and_index_obs{}'.format(str(year))]\n",
    "                case_df = all_df['case_index_date'].reset_index()\n",
    "\n",
    "                case_df['case_id'] =  case_df['case_id'].astype('Int64')\n",
    "                _cases_list['{}_yr_window'.format(str(year))] = {cp: case_df}\n",
    "\n",
    "                selected_columns = ['psm_control_{}'.format(str(mi)) for mi in range(1, match_ratio+1)]\n",
    "               \n",
    "                all_df[selected_columns] = all_df[selected_columns].astype('Int64')\n",
    "                control_melted = all_df.reset_index().melt(id_vars=['case_id'], value_vars=selected_columns, value_name='control_id').drop('variable', axis=1)\n",
    "                control_melted = control_melted[~control_melted['control_id'].isnull()]\n",
    "\n",
    "                case_control_index = _input_match_cci_collection['ADRD_filter_cci_match_and_index_obs{}'.format(str(year))]\n",
    "                control_index_melted = control_melted.merge(case_control_index, left_on=['case_id', 'control_id'],\\\n",
    "                                                            right_on=['case_person_id', 'control_person_id' ], how='left')\n",
    "\n",
    "                control_index_melted = control_index_melted[[ 'control_id', 'infer_index_date']]\n",
    "                control_index_melted.columns = ['control_id', 'control_index_date']\n",
    "                _controls_list['{}_yr_window'.format(str(year))] = {cp:control_index_melted} \n",
    "\n",
    "        return _cases_list, _controls_list\n",
    "        \n",
    "        \n",
    "    print('Summary of matched cohort: ')\n",
    "    summary(input_psm_match_collection, match_ratio)\n",
    "    \n",
    "    print('Format matched cohort ')\n",
    "    _psm_match_collection = format_psm_match(input_psm_match_collection, match_ratio)\n",
    "        \n",
    "    print('Format case and control lists ')\n",
    "\n",
    "    cases_list, controls_list = format_case_control_list(_psm_match_collection, input_match_cci_collection, match_ratio)\n",
    "    \n",
    "    return cases_list, controls_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb37ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratio = 10\n",
    "savepath = 'large_coa'\n",
    "input_match_cci_collection =    pickle.load( open('NewHome/cci_psm_match_90_ratio_{}_{}.pkl'.format(savepath, str(ratio)), 'rb'))\n",
    "input_psm_match_collection =    pickle.load( open('NewHome/psm_match_90_ratio_{}_{}.pkl'.format(savepath, str(ratio)), 'rb'))\n",
    "\n",
    "cases_list, controls_list = get_all_feature_for_psm_match(input_psm_match_collection, input_match_cci_collection, ratio)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f351fa4d",
   "metadata": {},
   "source": [
    "## get prediction time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "# get prediction time \n",
    "random.seed(4533421)\n",
    "\n",
    "year = 1\n",
    "    \n",
    "case_index = cases_list[f'{year}_yr_window'][1].rename(columns={'case_id':'patient_id', 'case_index_date':'index_date'})\n",
    "\n",
    "control_index = controls_list[f'{year}_yr_window'][1].rename(columns={'control_id':'patient_id', 'control_index_date':'index_date'})\n",
    "\n",
    "predict_date = pd.concat([case_index, control_index], axis=0)\n",
    "\n",
    "predict_date['prediction_time'] = predict_date['index_date'] - pd.DateOffset(years=year, days=1 if year==0 else 0)\n",
    "\n",
    "display(predict_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719cb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_index = dict(zip(predict_date.patient_id.values, [pd.Timestamp(d) for d in predict_date.prediction_time.values]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b2d9b",
   "metadata": {},
   "source": [
    "## filter data with this prediction window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d10969",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dxmotor |', dxmotor.shape)\n",
    "dxmotor_this_year = dxmotor[dxmotor.patient_id.isin(set(predict_date.patient_id.values.tolist()))]\n",
    "\n",
    "dxmotor_this_year['start'] = pd.to_datetime(dxmotor_this_year['start'])\n",
    "print('dxmotor this year |', dxmotor_this_year.shape,'\\n\\t', dxmotor_this_year['start'].dtype)\n",
    "\n",
    "dxmotor_1 = dxmotor_this_year[dxmotor_this_year.apply(lambda row: row['start'] < patient_index[row['patient_id']], axis=1)]\n",
    "print('dxmotor earlier than prediction |', dxmotor_1.shape)\n",
    "dxmotor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a972c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rxmotor |', rxmotor.shape)\n",
    "rxmotor_this_year = rxmotor[rxmotor.patient_id.isin(set(predict_date.patient_id.values.tolist()))]\n",
    "\n",
    "rxmotor_this_year['start'] = pd.to_datetime(rxmotor_this_year['start'])\n",
    "print('rxmotor this year |', rxmotor_this_year.shape,'\\n\\t', rxmotor_this_year['start'].dtype)\n",
    "\n",
    "rxmotor_1 = rxmotor_this_year[rxmotor_this_year.apply(lambda row: row['start'] < patient_index[row['patient_id']], axis=1)]\n",
    "print('dxmotor earlier than prediction |', rxmotor_1.shape)\n",
    "rxmotor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097cce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_motor = pd.concat([dxmotor_1, rxmotor_1], axis=0)\n",
    "\n",
    "cat_motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7fd55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_motor_patients = cat_motor.patient_id.nunique()\n",
    "print('patientts in motor', cat_motor_patients)\n",
    "\n",
    "date_range = cat_motor.groupby('patient_id')['start'].agg(['min', 'max'])\n",
    "date_range['EHR_length'] = (date_range['max'] - date_range['min']).dt.days / 365\n",
    "date_range = date_range[date_range['EHR_length']>=1]\n",
    "date_range_patients = date_range.index.values.tolist()\n",
    "date_range_patients_test = date_range_patients\n",
    "\n",
    "dx_motor_1_EHRs = dxmotor_1[dxmotor_1['patient_id'].isin(date_range_patients_test)]\n",
    "rx_motor_1_EHRs = rxmotor_1[rxmotor_1['patient_id'].isin(date_range_patients_test)]\n",
    "\n",
    "demo_1_EHRs = demographics_csv[demographics_csv['patient_id'].isin(date_range_patients_test)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447342f",
   "metadata": {},
   "source": [
    "##### save if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b537c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_date_1_EHRs = predict_date[predict_date['patient_id'].isin(date_range_patients_test)]\n",
    "predict_date_1_EHRs.to_csv(f'NewHome/trash/prediction_times_{year}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0796cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(f'NewHome/csvinput/year_{year}/'):\n",
    "    os.makedirs(f'NewHome/csvinput/year_{year}/')\n",
    "\n",
    "rx_motor_1_EHRs['value'] = None\n",
    "rx_motor_1_EHRs['units'] = None\n",
    "rx_motor_1_EHRs['dosage'] = None\n",
    "rx_motor_1_EHRs.to_csv(f'NewHome/csvinput/year_{year}/rxmotor.csv', sep=',', index=False)\n",
    "\n",
    "\n",
    "dx_motor_1_EHRs['value']=None\n",
    "dx_motor_1_EHRs['units']=None\n",
    "dx_motor_1_EHRs['dosage']=None\n",
    "dx_motor_1_EHRs.to_csv(f'NewHome/csvinput/year_{year}/dxmotor.csv', sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "demo_1_EHRs['value']=None\n",
    "demo_1_EHRs['units']=None\n",
    "demo_1_EHRs['dosage']=None\n",
    "demo_1_EHRs.to_csv(f'NewHome/csvinput/year_{year}/demographics_csv.csv', sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb61c9",
   "metadata": {},
   "source": [
    "\n",
    "## Convert to the extract directory\n",
    "We now convert the dataset we created above to an extract using the function [etl_simple_femr](https://github.com/som-shahlab/femr/blob/main/src/femr/etl_pipelines/simple.py#L66) from the femr repo\n",
    "\n",
    "We need to first create folders to save the dataset and associated files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b79539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "INPUT_DIR = f'NewHome/csvinput/year_{year}'\n",
    "\n",
    "TARGET_DIR = f'NewHome/trash/year_{year}'\n",
    "\n",
    "LOG_DIR = os.path.join(TARGET_DIR, \"logs\")\n",
    "EXTRACT_DIR = os.path.join(TARGET_DIR, \"extract\")\n",
    "\n",
    "\n",
    "if os.path.exists(TARGET_DIR):\n",
    "    shutil.rmtree(TARGET_DIR)\n",
    "\n",
    "os.mkdir(TARGET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a961b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import femr\n",
    "import femr.etl_pipelines.simple\n",
    "os.system(f\"etl_simple_femr {INPUT_DIR} {EXTRACT_DIR} {LOG_DIR} --num_threads 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eef507",
   "metadata": {},
   "source": [
    "## extract representation by motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab91b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import femr.datasets\n",
    "database = femr.datasets.PatientDatabase(f'NewHome/trash/year_{year}/extract')\n",
    "\n",
    "patients = list(database)\n",
    "\n",
    "print('example patient: ', patients[10])\n",
    "testpatient = database[patients[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02095aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls NewHome/motor_dir/\n",
    "\n",
    "!femr_compute_representations --data_path NewHome/trash/year_1/extract --model_path NewHome/motor_dir --prediction_times_path NewHome/trash/prediction_times_1.csv --batch_size 32 NewHome/motor_dir/motor_reprs_1.pkl\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
